{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBMClassifier\n",
    "---\n",
    "1. クレンジング処理\n",
    "2. StratifiedKFoldによる正負を均等に分割\n",
    "3. 交差ごとの学習とモデルの保存\n",
    "4. 閾値の探索\n",
    "5. 推論と提出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S7AH5rQh_3LM"
   },
   "outputs": [],
   "source": [
    "!pip install -q texthero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sDlsclKk_pHR"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from tqdm import tqdm \n",
    "import torch.nn as nn \n",
    "import torch \n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import os, time, pickle, json\n",
    "import texthero as hero\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from collections import Counter\n",
    "from typing import Dict, List, Any, Tuple, Union \n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from pprint import pprint \n",
    "import warnings\n",
    "from statistics import mean \n",
    "import random \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "okQTwpoQ_q8Y"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./raw/train.csv\")\n",
    "test = pd.read_csv(\"./raw/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## クレンジング処理\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PBSwjF1g_q53"
   },
   "outputs": [],
   "source": [
    "def create_tf_idf(df, dim:int=50, is_train=True)->pd.DataFrame:\n",
    "    df[\"abstract\"] = df[\"abstract\"].fillna(\" \")\n",
    "    df[\"contents\"] = df[\"title\"] + \" \" + df[\"abstract\"] \n",
    "    df.drop([\"title\", \"abstract\"], axis=1, inplace=True)\n",
    "    clean_text = hero.clean(df.contents, pipeline=[\n",
    "        hero.preprocessing.fillna,\n",
    "        hero.preprocessing.lowercase,\n",
    "        hero.preprocessing.remove_digits,\n",
    "        hero.preprocessing.remove_punctuation,\n",
    "        hero.preprocessing.remove_diacritics,\n",
    "        hero.preprocessing.remove_stopwords,\n",
    "        hero.preprocessing.remove_whitespace\n",
    "    ])\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(ngram_range=(1,2), min_df=5)),\n",
    "        ('svd', TruncatedSVD(n_components=dim, random_state=0)),\n",
    "    ])\n",
    "\n",
    "    out_df = pd.DataFrame(pipeline.fit_transform(clean_text), index=df.index).rename(\n",
    "        columns={i: \"content\"+'_'+str(i) for i in range(dim)})\n",
    "    if is_train:\n",
    "        out_df[\"judgement\"] = df[\"judgement\"]\n",
    "    \n",
    "    return out_df\n",
    "\n",
    "train = create_tf_idf(train)\n",
    "test = create_tf_idf(test, 50, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 交差分割\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9HUQjgWg_q3d"
   },
   "outputs": [],
   "source": [
    "def get_train_data(train):\n",
    "    '''正と負を均等に分割する'''\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    for n, (tr_id, va_id) in enumerate(kf.split(train, train.judgement)):\n",
    "        train.loc[va_id, \"fold\"] = int(n)\n",
    "    train[\"fold\"] = train.fold.astype(np.uint8)\n",
    "    return train\n",
    "\n",
    "train = get_train_data(train)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習と閾値探索\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bf4F-feI_q0T"
   },
   "outputs": [],
   "source": [
    "def train_fn(fold) -> Tuple[List[float], List[float]]:\n",
    "    train_ds = train[train.fold != fold]\n",
    "    val_ds = train[train.fold == fold]\n",
    "    x_train, y_train = train_ds.drop([\"fold\", \"judgement\"], axis=1), train_ds[[\"judgement\"]]\n",
    "    x_val, y_val = val_ds.drop([\"fold\", \"judgement\"], axis=1), val_ds[[\"judgement\"]]\n",
    "\n",
    "    model = LGBMClassifier(random_state=0).fit(x_train, y_train, eval_set=[(x_train, y_train), (x_val, y_val)], \n",
    "                                             early_stopping_rounds=100, verbose=0)\n",
    "    proba = model.predict_proba(x_val)[:, 1].tolist() # Positiveである確率\n",
    "    os.makedirs(\"models/\", exist_ok=True)\n",
    "    model.save_model(f\"models/lgb{fold}.model\")\n",
    "    return proba, y_val.values.ravel().tolist() \n",
    "\n",
    "def main():\n",
    "    '''\n",
    "    k分割したモデルの保存と、それぞれで予測された確率から最も評価の良い閾値の探索\n",
    "    '''\n",
    "    predict, correct = [], []\n",
    "    for fold in range(5):\n",
    "        proba, corr = train_fn(fold)\n",
    "        for p in proba:\n",
    "            predict.append(p)\n",
    "        for c in corr:\n",
    "            correct.append(c)\n",
    "    predict = np.array(predict)\n",
    "    \n",
    "    for threshold in np.arange(0.01, 0.2, 0.03):\n",
    "        pred = np.where(predict > threshold, 1, 0).astype(np.uint8).tolist()\n",
    "        f1 = f1_score(pred, correct)\n",
    "        pprint(classification_report(pred, correct))\n",
    "        result[str(threshold)] = f1 \n",
    "    return result \n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推論と提出\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qpgCwn0-_qt6"
   },
   "outputs": [],
   "source": [
    "def test_fn(fold) -> List[float]:\n",
    "    x_test = test[[\"contents\"]]\n",
    "    model = LGBMClassifier(random_state=0)\n",
    "    model.load_model(f\"models/lgb{fold}.model\")\n",
    "    proba = model.predict_proba(x_test)[:, 1].tolist()\n",
    "    del x_test \n",
    "    del model \n",
    "    return proba \n",
    "\n",
    "\n",
    "def inference(threshold: float) -> List[int]:\n",
    "    predict_proba = []\n",
    "    for fold in range(5):\n",
    "        # 5回のモデルの出力された確率平均を求める\n",
    "        proba = test_fn(fold)\n",
    "        predict_proba.append(proba)\n",
    "    predict_proba = np.array(predict_proba)\n",
    "    predict_proba = np.mean(predict_proba, axis=0)\n",
    "    predict = np.where(predict_proba > threshold, 1, 0).astype(np.uint8).tolist()\n",
    "    return predict\n",
    "\n",
    "def submittion(threshold):\n",
    "    predict = inference(threshold)\n",
    "    sub = pd.read_csv(\"./raw/sample_submit.csv\")\n",
    "    sub.columns = [\"id\", \"dummy\"]\n",
    "    sub = sub[[\"id\"]]\n",
    "    sub[\"predict\"] = predict \n",
    "    sub.to_csv(\"./raw/submit0914lgb.csv\", index=False, header=False)\n",
    "\n",
    "submittion(threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L_3zbFyi_qh3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
